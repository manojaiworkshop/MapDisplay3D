#!/bin/bash
# Quick reference guide for the multi-provider LLM system

cat << 'EOF'
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ðŸ¤– Multi-Provider LLM System - Quick Guide            â•‘
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“‹ SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Implementation: COMPLETE
âœ… 4 Providers: OpenAI | Ollama | vLLM | Anthropic
âœ… Dynamic Switching: Yes (runtime, no restart needed)
âœ… UI Component: Beautiful selector with status indicators
âœ… Fallback System: Auto-regex parser on LLM failure
âœ… API Endpoints: 3 new endpoints for provider management

ðŸš€ QUICK START
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£  RESTART BACKEND (Important!)
   cd webapp/backend
   # Stop current backend (Ctrl+C in python terminal)
   python main.py

2ï¸âƒ£  START FRONTEND
   cd webapp/frontend
   npm run dev

3ï¸âƒ£  OPEN BROWSER
   http://localhost:3000

4ï¸âƒ£  FIND LLM SELECTOR
   Look for "ðŸ¤– LLM Provider" in chat panel
   Click to expand â†’ See all providers
   Click any available provider to switch

ðŸ“¡ API ENDPOINTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

GET  /api/llm/providers
     â†’ List all providers with status

POST /api/llm/switch-provider
     Body: {"provider": "ollama"}
     â†’ Switch active provider

GET  /api/llm/status
     â†’ Current provider status

POST /api/interpret-command
     Body: {"text": "zoom to 10x"}
     â†’ Parse command (now with provider info)

ðŸ§ª TESTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Option 1: Simple Test (After restarting backend)
   ./test_simple.sh

Option 2: Full Test (After restarting backend)
   ./test_llm_providers.sh

Option 3: Manual cURL
   curl http://localhost:8088/api/llm/providers
   curl -X POST http://localhost:8088/api/llm/switch-provider \
     -H "Content-Type: application/json" \
     -d '{"provider": "ollama"}'

âš™ï¸  CONFIGURATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Edit: config.yaml

llm:
  provider: ollama        # Default provider
  fallback_to_rules: true # Use regex if LLM fails

ollama:
  api_url: http://localhost:11434/api/chat
  model: mistral:latest
  
openai:
  api_key: "sk-..."
  model: gpt-4o-mini-2024-07-18

ðŸ“¦ PROVIDERS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Provider    â”‚ Cost     â”‚ Speed   â”‚ Privacy  â”‚ Quality  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ OpenAI      â”‚ Paid     â”‚ Fast    â”‚ Cloud    â”‚ Excellentâ”‚
â”‚ Ollama      â”‚ FREE âœ“   â”‚ Medium  â”‚ Local âœ“  â”‚ Good     â”‚
â”‚ vLLM        â”‚ Varies   â”‚ Fast    â”‚ Custom   â”‚ Varies   â”‚
â”‚ Anthropic   â”‚ Paid     â”‚ Fast    â”‚ Cloud    â”‚ Excellentâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸŽ¨ UI FEATURES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Status Indicators:
  ðŸŸ¢ Green  â†’ Active and ready
  âšª White  â†’ Available but inactive
  ðŸ”´ Red    â†’ Offline/not configured

Auto-refresh: Every 30 seconds
One-click switching: No confirmation needed
Collapse/expand: Click header to toggle

ðŸ”§ TROUBLESHOOTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âŒ "Not Found" errors?
   â†’ Backend needs restart! Stop and run: python main.py

âŒ Ollama not available?
   â†’ ollama serve
   â†’ ollama pull mistral:latest

âŒ OpenAI not available?
   â†’ Check API key in config.yaml

âŒ JSON parsing errors?
   â†’ Fallback parser activates automatically
   â†’ Commands still work!

ðŸ“š DOCUMENTATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

LLM_PROVIDER_GUIDE.md       â†’ Complete guide
MULTI_PROVIDER_README.md    â†’ Quick start
IMPLEMENTATION_COMPLETE.md  â†’ Technical summary

ðŸŽ‰ SUCCESS CHECKLIST
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Dependencies installed (pip install -r requirements.txt)
âœ… Backend restarted with new code
âœ… Frontend running (npm run dev)
âœ… Can see provider selector in UI
âœ… Can switch providers
âœ… Commands work with different providers

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ðŸ’¡ TIP: The backend MUST be restarted to load the new endpoints!
     Press Ctrl+C in the python terminal, then run: python main.py

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF
